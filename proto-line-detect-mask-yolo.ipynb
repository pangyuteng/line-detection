{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "set_random_seed(SEED)\n",
    "rn.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_line import make_data, get_grid, get_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x  (None,64,64)\n",
    "# y0 (None,8,8,5)     - object,relstartx,relstarty,shapex,shapey\n",
    "# y1 (None, (8,8) or 64,64,64) mask\n",
    "\n",
    "szx,szy,szz=64,64,64\n",
    "smx,smy=8,8\n",
    "x_train, y_train0, y_train1 = make_data(N=1024)\n",
    "x_val, y_val0, y_val1 = make_data(N=100)\n",
    "x_test, y_test0, y_test1 = make_data(N=5)\n",
    "grid, grid_anchor = get_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff6eac00eb8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = -2\n",
    "plt.subplot(121)\n",
    "plt.imshow(x_train[ind,:].squeeze())\n",
    "region = np.argwhere(y_train0[ind,:,:,-1]==1)\n",
    "print(region)\n",
    "tmp = np.zeros((szx,szy))\n",
    "r=1\n",
    "if len(region.squeeze().shape) > 0:\n",
    "    for x,y in region:\n",
    "        code = smx*x+y\n",
    "        print(code,x,smx,y,np.sum(y_train1[ind,x,y,code]))\n",
    "        tmp[y_train1[ind,:,:,code].squeeze()==1]=r+1\n",
    "        r+=1\n",
    "plt.subplot(122)\n",
    "plt.imshow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import optimizers as opt\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Reshape, Conv2DTranspose, UpSampling2D\n",
    "from keras.callbacks import LearningRateScheduler,EarlyStopping\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Permute, Reshape, Lambda, add, Input, Concatenate\n",
    "from keras.layers import Conv2D, BatchNormalization, LeakyReLU\n",
    "from keras import regularizers, initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viz_results(x_test,y_test0,ytest1,pred,szx,szy):\n",
    "    obj_ind = -1\n",
    "    #for ind in range(pred.shape[0]):\n",
    "    for ind in range(5):\n",
    "\n",
    "        plt.figure(ind,figsize=(20,10))\n",
    "        #print(pred[0][ind,:,:,obj_ind])\n",
    "        maxval = np.max(pred[0][ind,:,:,obj_ind])\n",
    "        argmax = np.argwhere(pred[0][ind,:,:,obj_ind]==maxval)\n",
    "        argmaxx,argmaxy=argmax[0]\n",
    "        print(print(argmax.shape),argmax[0])\n",
    "        \n",
    "        print('pred',pred[0][ind,argmaxx,argmaxy,:])\n",
    "        print('true',y_test0[ind,argmaxx,argmaxy,:])\n",
    "        print('------')\n",
    "        \n",
    "        # GROUND TRUTH\n",
    "        sa=plt.subplot(331)\n",
    "        plt.title('sample index: {}, t:green, p:blue'.format(ind))\n",
    "        sa.imshow(x_test[ind,:].squeeze())\n",
    "        \n",
    "        # overlay bounding box\n",
    "        argmax = get_code(argmaxx,argmaxy,smx)\n",
    "        ax,ay=grid_anchor[argmax]\n",
    "        x,y,w,h,o = pred[0][ind,argmaxx,argmaxy,:]\n",
    "        x,y,w,h,o = x*szx,y*szy,w*szx,h*szy,o\n",
    "        x,y = ax+x,ay+y\n",
    "        x,y = x-w/2.,y-h/2.\n",
    "        rect = patches.Rectangle((y,x),h,w,linewidth=2,edgecolor='b',facecolor='none')\n",
    "        sa.add_patch(rect)\n",
    "        \n",
    "        x,y,w,h,o = y_test0[ind,argmaxx,argmaxy,:]\n",
    "        x,y,w,h,o = x*szx,y*szy,w*szx,h*szy,o\n",
    "        x,y = ax+x,ay+y\n",
    "        x,y = x-w/2.,y-h/2.\n",
    "        rect = patches.Rectangle((y,x),h,w,linewidth=2,edgecolor='g',facecolor='none')\n",
    "        sa.add_patch(rect)\n",
    "        \n",
    "        obj_real = y_test0[ind,:,:,obj_ind].squeeze()\n",
    "        \n",
    "        plt.subplot(332)\n",
    "        plt.title('obj or not - truth'.format())\n",
    "        plt.imshow(obj_real,cmap='gray')\n",
    "        \n",
    "        ax = plt.subplot(333)\n",
    "        plt.title('obj or not - truth - actual val'.format())\n",
    "        plt.plot(obj_real.ravel())\n",
    "        ax.set_ylim(0,1)\n",
    "        \n",
    "        # PREDICTED\n",
    "        \n",
    "        obj = pred[0][ind,:,:,obj_ind].squeeze()\n",
    "        \n",
    "        plt.subplot(334)\n",
    "        plt.title('obj or not - pred'.format())\n",
    "        plt.imshow(obj,cmap='gray')\n",
    "        plt.subplot(335)\n",
    "        plt.title('obj or not - pred - actual val'.format())\n",
    "        plt.imshow(obj,vmin=0,vmax=1,cmap='gray')\n",
    "        \n",
    "        ax = plt.subplot(336)\n",
    "        plt.title('obj or not - pred - actual val'.format())\n",
    "        plt.plot(obj.ravel())\n",
    "        ax.set_ylim(0,1)\n",
    "\n",
    "        if len(pred)>1:\n",
    "            plt.subplot(337)\n",
    "            plt.title('mask - pred'.format())\n",
    "            \n",
    "            plt.title('argmax {}'.format(argmax))\n",
    "            plt.imshow(pred[1][ind,:,:,argmax].squeeze(),cmap='gray')\n",
    "            #plt.imshow(pred[1][ind,argmaxx,argmaxy,:,:].squeeze(),cmap='gray')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/48810639/how-can-i-create-an-image-mask-tensor-from-unknown-number-of-bounding-boxes\n",
    "USE_FOLD = True\n",
    "\n",
    "def box_mask(box):\n",
    "  \"\"\"Create a 4x4 tensor of zeros except for a rectangle of ones defined by `box`\"\"\"\n",
    "  x, y = 4, 4\n",
    "  ymin, xmin, ymax, xmax = tf.unstack(box)\n",
    "  h = xmax - xmin\n",
    "  z0 = tf.zeros([xmin, y])\n",
    "  z1 = tf.concat(\n",
    "      [tf.zeros([h, ymin]),\n",
    "       tf.ones([h, ymax - ymin]),\n",
    "       tf.zeros([h, y - ymax])],\n",
    "      axis=1)\n",
    "  z2 = tf.zeros([x - xmax, y])\n",
    "  return tf.concat([z0, z1, z2], axis=0)\n",
    "\n",
    "def reduce_mask(a, box):\n",
    "  mask = box_mask(box)\n",
    "  return tf.maximum(a, mask)\n",
    "\n",
    "def run():\n",
    "  boxes_val = np.array([[0, 0, 2, 2], [2, 2, 4, 4]])\n",
    "  boxes = tf.placeholder(shape=(None, 4), dtype=tf.int32)\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    if USE_FOLD:\n",
    "      print(sess.run(tf.foldl(reduce_mask, boxes,\n",
    "                              initializer=tf.zeros([4,4])),\n",
    "                     feed_dict={boxes: boxes_val}))\n",
    "    else:\n",
    "      masks = tf.map_fn(box_mask, boxes, dtype=tf.float32)\n",
    "      combined_mask = tf.reduce_max(masks, axis=0)\n",
    "      print(sess.run(combined_mask, feed_dict={boxes: boxes_val}))\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 64, 64, 16)   144         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 64, 64, 16)   64          conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_109 (LeakyReLU)     (None, 64, 64, 16)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 32, 32, 16)   0           leaky_re_lu_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 32, 32, 16)   0           max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 32, 32, 32)   4608        dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 32)   128         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_110 (LeakyReLU)     (None, 32, 32, 32)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 16, 16, 32)   0           leaky_re_lu_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 32)   0           max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 16, 16, 64)   18432       dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 64)   256         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_111 (LeakyReLU)     (None, 16, 16, 64)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 16, 16, 32)   2048        leaky_re_lu_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 32)   128         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_112 (LeakyReLU)     (None, 16, 16, 32)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 16, 16, 64)   18432       leaky_re_lu_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   256         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_113 (LeakyReLU)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 8, 8, 64)     0           leaky_re_lu_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 8, 8, 64)     0           max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 128)    73728       dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 8, 8, 128)    512         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_114 (LeakyReLU)     (None, 8, 8, 128)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 64)     8192        leaky_re_lu_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 8, 8, 64)     256         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)     (None, 8, 8, 64)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 128)    73728       leaky_re_lu_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 8, 8, 128)    512         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_116 (LeakyReLU)     (None, 8, 8, 128)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 8, 8, 128)    0           leaky_re_lu_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 64)     8192        dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 8, 8, 64)     256         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_117 (LeakyReLU)     (None, 8, 8, 64)     0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 128)    73728       leaky_re_lu_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 8, 8, 128)    512         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_118 (LeakyReLU)     (None, 8, 8, 128)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 5)      640         leaky_re_lu_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "VECTOR (Activation)             (None, 8, 8, 5)      0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 69)     0           dropout_37[0][0]                 \n",
      "                                                                 VECTOR[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_30 (Conv2DTran (None, 8, 8, 64)     39744       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 8, 8, 64)     256         conv2d_transpose_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_119 (LeakyReLU)     (None, 8, 8, 64)     0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DTran (None, 8, 8, 32)     2048        leaky_re_lu_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 8, 32)     128         conv2d_transpose_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_120 (LeakyReLU)     (None, 8, 8, 32)     0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_32 (Conv2DTran (None, 8, 8, 64)     18432       leaky_re_lu_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 8, 64)     256         conv2d_transpose_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_121 (LeakyReLU)     (None, 8, 8, 64)     0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, 16, 16, 64)   0           leaky_re_lu_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_33 (Conv2DTran (None, 16, 16, 32)   18432       up_sampling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 32)   128         conv2d_transpose_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_122 (LeakyReLU)     (None, 16, 16, 32)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling2D) (None, 32, 32, 32)   0           leaky_re_lu_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_34 (Conv2DTran (None, 32, 32, 16)   4608        up_sampling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 32, 32, 16)   64          conv2d_transpose_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_123 (LeakyReLU)     (None, 32, 32, 16)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D) (None, 64, 64, 16)   0           leaky_re_lu_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 64, 64, 64)   1024        up_sampling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "MASK (Activation)               (None, 64, 64, 64)   0           conv2d_104[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 369,872\n",
      "Trainable params: 368,016\n",
      "Non-trainable params: 1,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "set_random_seed(SEED)\n",
    "rn.seed(SEED)\n",
    "\n",
    "# actual yolos\n",
    "#   https://pjreddie.com/media/files/papers/YOLO9000.pdf GOOD, others are helpful\n",
    "#   https://github.com/ksanjeevan/dourflow/blob/master/net/netarch.py\n",
    "#   https://github.com/guigzzz/Keras-Yolo-v2\n",
    "#   https://hackernoon.com/understanding-yolo-f5a74bbc7967\n",
    "# simple yolo # less intimidating, but not useable, good for intro.\n",
    "#   https://gist.github.com/msrks/ce613e91a98868d4a059c6c5c5e30ba3\n",
    "# vanillay conv cannot prediction coord\n",
    "#   https://eng.uber.com/coordconv/\n",
    "# alternative archetectures.\n",
    "#   https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e\n",
    "#   https://github.com/jianing-sun/Mask-YOLO\n",
    "\n",
    "epsilon = 1E-8\n",
    "def compute_obj_loss(y_true,y_pred):\n",
    "    return tf.reduce_mean(tf.keras.backend.binary_crossentropy(y_true[...,-1], y_pred[...,-1]))\n",
    "\n",
    "def compute_coord_loss(y_true,y_pred):\n",
    "    loss_px = tf.squared_difference(y_true[...,0],y_pred[...,0])\n",
    "    loss_py = tf.squared_difference(y_true[...,1],y_pred[...,1])\n",
    "    loss_wx = tf.squared_difference(y_true[...,2],y_pred[...,2])\n",
    "    loss_wy = tf.squared_difference(y_true[...,3],y_pred[...,3])\n",
    "    \n",
    "    loss_pos = tf.add(loss_px,loss_py)\n",
    "    loss_width = tf.add(loss_wx,loss_wy)\n",
    "    \n",
    "    coord_loss = tf.add(loss_pos,loss_width)\n",
    "    coord_loss = tf.multiply(y_true[...,-1],coord_loss)\n",
    "    return tf.reduce_mean(coord_loss)\n",
    "\n",
    "def compute_iou_loss(y_true,y_pred):\n",
    "    # ref. https://github.com/ksanjeevan/dourflow/blob/master/net/netloss.py\n",
    "    def process_boxes(A):\n",
    "        # ALign x-w, y-h\n",
    "        A_xy = A[..., 0:2]\n",
    "        A_wh = A[..., 2:4]\n",
    "        \n",
    "        A_wh_half = A_wh / 2.\n",
    "        # Get x_min, y_min\n",
    "        A_mins = A_xy - A_wh_half\n",
    "        # Get x_max, y_max\n",
    "        A_maxes = A_xy + A_wh_half\n",
    "        \n",
    "        return A_mins, A_maxes, A_wh\n",
    "    \n",
    "    # Process two sets\n",
    "    A2_mins, A2_maxes, A2_wh = process_boxes(y_pred)\n",
    "    A1_mins, A1_maxes, A1_wh = process_boxes(y_true)\n",
    "    \n",
    "    # Intersection as min(Upper1, Upper2) - max(Lower1, Lower2)\n",
    "    intersect_mins  = K.maximum(A2_mins,  A1_mins)\n",
    "    intersect_maxes = K.minimum(A2_maxes, A1_maxes)\n",
    "    \n",
    "    # Getting the intersections in the xy (aka the width, height intersection)\n",
    "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "\n",
    "    # Multiply to get intersecting area\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    # Values for the single sets\n",
    "    true_areas = A1_wh[..., 0] * A1_wh[..., 1]\n",
    "    pred_areas = A2_wh[..., 0] * A2_wh[..., 1]\n",
    "    \n",
    "    # Compute union for the IoU\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    \n",
    "    # probably not necssary...\n",
    "    iou_loss = tf.multiply(y_true[...,-1], 1. - tf.truediv(intersect_areas,(union_areas+epsilon)) )\n",
    "    \n",
    "    return tf.reduce_mean(iou_loss)\n",
    "\n",
    "def vec_loss(y_true, y_pred):\n",
    "    \n",
    "    lambda_obj = 1.0\n",
    "    lambda_coord = 0.1\n",
    "    lambda_iou = 1.0\n",
    "    \n",
    "    obj_loss = compute_obj_loss(y_true, y_pred)\n",
    "    obj_loss = tf.multiply(lambda_obj,obj_loss)\n",
    "    \n",
    "    coord_loss = compute_coord_loss(y_true, y_pred)\n",
    "    coord_loss = tf.multiply(lambda_coord,coord_loss)\n",
    "    \n",
    "    iou_loss = compute_iou_loss(y_true, y_pred)\n",
    "    iou_loss = tf.multiply(lambda_iou,iou_loss)\n",
    "    \n",
    "    total_loss = tf.add(tf.add(obj_loss,coord_loss),iou_loss)\n",
    "    \n",
    "    return tf.reduce_mean(total_loss)\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/3611\n",
    "def dice_coef(y_true, y_pred, smooth=1e-3):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2])\n",
    "    union = K.sum(y_true, axis=[1,2]) + K.sum(y_pred, axis=[1,2])\n",
    "    return (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):    \n",
    "    dice = 1-dice_coef(y_true, y_pred)\n",
    "    # get rid of dice where there is no object.\n",
    "    is_obj = K.sum(y_true, axis=[1,2])\n",
    "    is_obj = K.greater(is_obj,0.5*K.ones_like(is_obj))\n",
    "    dice = tf.boolean_mask(dice, is_obj)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "def conv_batch_lrelu(input_tensor, numfilter, dim, strides=1):\n",
    "    # https://github.com/guigzzz/Keras-Yolo-v2/blob/f61286371cdc2d470e0811234f552c70bbd5caba/yolo_layer_utils.py#L18\n",
    "    input_tensor = Conv2D(numfilter, (dim, dim), strides=strides, padding='same',\n",
    "                        kernel_regularizer=regularizers.l2(0.0005),\n",
    "                        kernel_initializer=initializers.TruncatedNormal(stddev=0.1),\n",
    "                        use_bias=False\n",
    "                    )(input_tensor)\n",
    "    input_tensor = BatchNormalization()(input_tensor)\n",
    "    return LeakyReLU(alpha=0.1)(input_tensor)\n",
    "\n",
    "def convt_batch_lrelu(input_tensor, numfilter, dim, strides=1):\n",
    "    input_tensor = Conv2DTranspose(numfilter, (dim, dim), strides=strides, padding='same',\n",
    "                        kernel_regularizer=regularizers.l2(0.0005),\n",
    "                        kernel_initializer=initializers.TruncatedNormal(stddev=0.1),\n",
    "                        use_bias=False\n",
    "                    )(input_tensor)\n",
    "    input_tensor = BatchNormalization()(input_tensor)\n",
    "    return LeakyReLU(alpha=0.1)(input_tensor)\n",
    "\n",
    "MASK = 'MASK'\n",
    "VECTOR = 'VECTOR'\n",
    "\n",
    "inputs = Input(shape=(szx,szy,1))\n",
    "\n",
    "dropoutrate = 0.4\n",
    "\n",
    "# down sample\n",
    "xd = conv_batch_lrelu(inputs, 16, 3)\n",
    "xd = MaxPooling2D(pool_size=(2, 2),strides=2)(xd)\n",
    "xd=Dropout(dropoutrate)(xd)\n",
    "xd = conv_batch_lrelu(xd, 32, 3)\n",
    "xd = MaxPooling2D(pool_size=(2, 2),strides=2)(xd)\n",
    "xd=Dropout(dropoutrate)(xd)\n",
    "xd = conv_batch_lrelu(xd, 64, 3)\n",
    "xd = conv_batch_lrelu(xd, 32, 1)\n",
    "xd = conv_batch_lrelu(xd, 64, 3)\n",
    "xd = MaxPooling2D(pool_size=(2, 2),strides=2)(xd)\n",
    "xd=Dropout(dropoutrate)(xd)\n",
    "\n",
    "# to coord & obj\n",
    "xb = conv_batch_lrelu(xd, 128, 3)\n",
    "xb = conv_batch_lrelu(xb, 64, 1)\n",
    "xb = conv_batch_lrelu(xb, 128, 3)\n",
    "xb = Dropout(dropoutrate)(xb)\n",
    "xb = conv_batch_lrelu(xb, 64, 1)\n",
    "xb = conv_batch_lrelu(xb, 128, 3)\n",
    "xb = Conv2D(5, (1, 1), strides=1, padding='same',use_bias=False)(xb)\n",
    "vecs=Activation('sigmoid',name=VECTOR)(xb)\n",
    "\n",
    "# up sample\n",
    "merged = Concatenate(axis=-1,)([xd,vecs])\n",
    "xu = convt_batch_lrelu(merged, 64, 3) # can just use conv_batch_lrelu if using upsampling2d...\n",
    "xu = convt_batch_lrelu(xu, 32, 1)\n",
    "xu = convt_batch_lrelu(xu, 64, 3)\n",
    "xu = UpSampling2D(size=(2,2),interpolation='nearest')(xu)\n",
    "xu = convt_batch_lrelu(xu, 32, 3)\n",
    "xu = UpSampling2D(size=(2,2),interpolation='nearest')(xu)\n",
    "xu = convt_batch_lrelu(xu, 16, 3)\n",
    "xu = UpSampling2D(size=(2,2),interpolation='nearest')(xu)\n",
    "\n",
    "'''\n",
    "#for k,v in grid.items():\n",
    "#    print(get_code(x,y,smx),v)\n",
    "#ax,ay=grid_anchor[(x,y)]\n",
    "\n",
    "# make \n",
    "def get_boxed(vecs):\n",
    "    # convert 8x8,5 to 64,5\n",
    "    # make mask, 64x64,64\n",
    "    # draw box per mask\n",
    "    \n",
    "    med_x = vecs[...,0]\n",
    "    med_y = vecs[...,1]\n",
    "    dim_x = vecs[...,2]\n",
    "    dim_y = vecs[...,3]\n",
    "    isobj = vecs[...,4]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if code not in anchor_dict.keys():\n",
    "    anchor_dict[code]=(x,y)\n",
    "grid[(x,y)]=(code,px,py)\n",
    "get_code(px,py,smx):\n",
    "    \n",
    "    vecs\n",
    "boxes = get_boxed(vecs)\n",
    "\n",
    "xu = Concatenate(axis=-1,)([xu,boxes])\n",
    "'''\n",
    "\n",
    "xu = Conv2D(64, (1, 1), strides=1, padding='same',use_bias=False)(xu)\n",
    "masks=Activation('sigmoid',name=MASK)(xu)\n",
    "\n",
    "# merge outputs\n",
    "model = Model(inputs=inputs, outputs=[vecs,masks])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1024 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 2.6047 - VECTOR_loss: 0.3747 - MASK_loss: 0.9707 - val_loss: 2.3188 - val_VECTOR_loss: 0.2439 - val_MASK_loss: 0.9711\n",
      "Epoch 2/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 2.1432 - VECTOR_loss: 0.1956 - MASK_loss: 0.9684 - val_loss: 2.0098 - val_VECTOR_loss: 0.1794 - val_MASK_loss: 0.9711\n",
      "Epoch 3/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.9014 - VECTOR_loss: 0.1689 - MASK_loss: 0.9643 - val_loss: 1.8227 - val_VECTOR_loss: 0.1719 - val_MASK_loss: 0.9700\n",
      "Epoch 4/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.7310 - VECTOR_loss: 0.1589 - MASK_loss: 0.9585 - val_loss: 1.6826 - val_VECTOR_loss: 0.1648 - val_MASK_loss: 0.9691\n",
      "Epoch 5/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.6032 - VECTOR_loss: 0.1534 - MASK_loss: 0.9515 - val_loss: 1.5772 - val_VECTOR_loss: 0.1613 - val_MASK_loss: 0.9668\n",
      "Epoch 6/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.5009 - VECTOR_loss: 0.1475 - MASK_loss: 0.9433 - val_loss: 1.4962 - val_VECTOR_loss: 0.1588 - val_MASK_loss: 0.9655\n",
      "Epoch 7/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.4177 - VECTOR_loss: 0.1438 - MASK_loss: 0.9327 - val_loss: 1.4174 - val_VECTOR_loss: 0.1480 - val_MASK_loss: 0.9585\n",
      "Epoch 8/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.3470 - VECTOR_loss: 0.1409 - MASK_loss: 0.9195 - val_loss: 1.3671 - val_VECTOR_loss: 0.1494 - val_MASK_loss: 0.9553\n",
      "Epoch 9/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.2847 - VECTOR_loss: 0.1383 - MASK_loss: 0.9035 - val_loss: 1.3238 - val_VECTOR_loss: 0.1556 - val_MASK_loss: 0.9449\n",
      "Epoch 10/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.2251 - VECTOR_loss: 0.1358 - MASK_loss: 0.8817 - val_loss: 1.3079 - val_VECTOR_loss: 0.1644 - val_MASK_loss: 0.9516\n",
      "Epoch 11/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.1695 - VECTOR_loss: 0.1339 - MASK_loss: 0.8562 - val_loss: 1.2246 - val_VECTOR_loss: 0.1491 - val_MASK_loss: 0.9087\n",
      "Epoch 12/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.1180 - VECTOR_loss: 0.1321 - MASK_loss: 0.8291 - val_loss: 1.1731 - val_VECTOR_loss: 0.1433 - val_MASK_loss: 0.8828\n",
      "Epoch 13/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.0719 - VECTOR_loss: 0.1309 - MASK_loss: 0.8022 - val_loss: 1.0803 - val_VECTOR_loss: 0.1356 - val_MASK_loss: 0.8137\n",
      "Epoch 14/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 1.0308 - VECTOR_loss: 0.1289 - MASK_loss: 0.7774 - val_loss: 1.1153 - val_VECTOR_loss: 0.1470 - val_MASK_loss: 0.8502\n",
      "Epoch 15/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.9907 - VECTOR_loss: 0.1262 - MASK_loss: 0.7517 - val_loss: 0.9976 - val_VECTOR_loss: 0.1334 - val_MASK_loss: 0.7566\n",
      "Epoch 16/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.9567 - VECTOR_loss: 0.1246 - MASK_loss: 0.7288 - val_loss: 0.9935 - val_VECTOR_loss: 0.1367 - val_MASK_loss: 0.7577\n",
      "Epoch 17/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.9295 - VECTOR_loss: 0.1219 - MASK_loss: 0.7119 - val_loss: 0.9666 - val_VECTOR_loss: 0.1317 - val_MASK_loss: 0.7426\n",
      "Epoch 18/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.9043 - VECTOR_loss: 0.1188 - MASK_loss: 0.6962 - val_loss: 0.9562 - val_VECTOR_loss: 0.1346 - val_MASK_loss: 0.7352\n",
      "Epoch 19/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.8843 - VECTOR_loss: 0.1181 - MASK_loss: 0.6821 - val_loss: 0.9033 - val_VECTOR_loss: 0.1262 - val_MASK_loss: 0.6953\n",
      "Epoch 20/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.8632 - VECTOR_loss: 0.1151 - MASK_loss: 0.6684 - val_loss: 0.8977 - val_VECTOR_loss: 0.1259 - val_MASK_loss: 0.6943\n",
      "Epoch 21/1000\n",
      "1024/1024 [==============================] - 2s 2ms/step - loss: 0.8480 - VECTOR_loss: 0.1133 - MASK_loss: 0.6588 - val_loss: 0.8839 - val_VECTOR_loss: 0.1249 - val_MASK_loss: 0.6848\n",
      "Epoch 22/1000\n",
      " 800/1024 [======================>.......] - ETA: 0s - loss: 0.8356 - VECTOR_loss: 0.1121 - MASK_loss: 0.6504"
     ]
    }
   ],
   "source": [
    "\n",
    "yolo_loss = {\n",
    "    MASK: dice_coef_loss,\n",
    "    VECTOR: vec_loss,\n",
    "}\n",
    "loss_weights = {\n",
    "    MASK: 1.,\n",
    "    VECTOR: 1.,\n",
    "}\n",
    "\n",
    "verbose=1\n",
    "batch_size=32\n",
    "epochs=1000\n",
    "lr=1E-3\n",
    "decay=1E-3\n",
    "patience=10\n",
    "beta_1=0.9\n",
    "beta_2=0.999\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=patience,\n",
    "                              verbose=0,\n",
    "                              mode='min')\n",
    "\n",
    "callbacks = [early_stopping]\n",
    "optimizer = opt.Adam(lr=lr,beta_1=beta_1, beta_2=beta_2, decay=decay)\n",
    "model.compile(loss=yolo_loss, loss_weights=loss_weights, optimizer=optimizer)\n",
    "history = model.fit(x_train, {VECTOR:y_train0,MASK:y_train1},\n",
    "                    batch_size=batch_size, epochs=epochs,\n",
    "                    verbose=verbose, \n",
    "                    validation_data=(x_val, {VECTOR:y_val0, MASK:y_val1}),\n",
    "                    callbacks=callbacks)\n",
    "# no merge \n",
    "# 0.9,1.1\n",
    "# merge at 8x8\n",
    "# 0.6, 0.7\n",
    "# bug fix, dice sum axis (from 2,3 to 1,2), and is_obj > 0 from to is_obj > 0.5\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0, y_0, y_1 = x_train, y_train0, y_train1\n",
    "out = model.evaluate(x_0,{VECTOR:y_0, MASK:y_1})\n",
    "print('train',out)\n",
    "x_0, y_0, y_1 = x_val, y_val0, y_val1\n",
    "out = model.evaluate(x_0,{VECTOR:y_0, MASK:y_1})\n",
    "print('val',out)\n",
    "x_0, y_0, y_1 = x_test, y_test0, y_test1\n",
    "out = model.evaluate(x_0,{VECTOR:y_0, MASK:y_1})\n",
    "print('test',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_0, y_0, y_1 = x_test, y_test0, y_test1\n",
    "#x_0, y_0, y_1 = x_train, y_train0, y_train1\n",
    "#x_0, y_0, y_1 = x_val, y_val0, y_val1\n",
    "pred = model.predict(x_0)\n",
    "viz_results(x_0,y_0,y_1,pred,szx,szy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
